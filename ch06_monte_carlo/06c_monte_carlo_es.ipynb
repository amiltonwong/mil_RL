{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: monte_carlo_es.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from grid_world import standard_grid, negative_grid\n",
    "from iterative_policy_evaluation import print_values, print_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this script implements the Monte Carlo Exploring-Starts method\n",
    "#       for finding the optimal policy\n",
    "\n",
    "def play_game(grid, policy):\n",
    "    # returns a list of states and corresponding returns\n",
    "\n",
    "    # reset game to start at a random position\n",
    "    # we need to do this if we have a deterministic policy\n",
    "    # we would never end up at certain states, but we still want to measure their value\n",
    "    # this is called the \"exploring starts\" method\n",
    "    start_states = grid.actions.keys()\n",
    "    start_idx = np.random.choice(len(start_states))\n",
    "    grid.set_state(start_states[start_idx])\n",
    "\n",
    "    s = grid.current_state()\n",
    "    a = np.random.choice(ALL_POSSIBLE_ACTIONS) # first action is uniformly random\n",
    "\n",
    "    # be aware of the timing\n",
    "    # each triple is s(t), a(t), r(t)\n",
    "    # but r(t) results from taking action a(t-1) from s(t-1) and landing in s(t)\n",
    "    states_actions_rewards = [(s, a, 0)]\n",
    "    seen_states = set()\n",
    "    while True:\n",
    "        old_s = grid.current_state()\n",
    "        r = grid.move(a)\n",
    "        s = grid.current_state()\n",
    "\n",
    "        if s in seen_states:\n",
    "            # hack so that we don't end up in an infinitely long episode\n",
    "            # bumping into the wall repeatedly\n",
    "            states_actions_rewards.append((s, None, -100))\n",
    "            break\n",
    "        elif grid.game_over():\n",
    "            states_actions_rewards.append((s, None, r))\n",
    "            break\n",
    "        else:\n",
    "            a = policy[s]\n",
    "            states_actions_rewards.append((s, a, r))\n",
    "        seen_states.add(s)\n",
    "\n",
    "    # calculate the returns by working backwards from the terminal state\n",
    "    G = 0\n",
    "    states_actions_returns = []\n",
    "    first = True\n",
    "    for s, a, r in reversed(states_actions_rewards):\n",
    "        # the value of the terminal state is 0 by definition\n",
    "        # we should ignore the first state we encounter\n",
    "        # and ignore the last G, which is meaningless since it doesn't correspond to any move\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            states_actions_returns.append((s, a, G))\n",
    "        G = r + GAMMA*G\n",
    "    states_actions_returns.reverse() # we want it to be in order of state visited\n",
    "    return states_actions_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_dict(d):\n",
    "    # returns the argmax (key) and max (value) from a dictionary\n",
    "    # put this into a function since we are using it so often\n",
    "    max_key = None\n",
    "    max_val = float('-inf')\n",
    "    for k, v in d.iteritems():\n",
    "        if v > max_val:\n",
    "            max_val = v\n",
    "            max_key = k\n",
    "    return max_key, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.90| -0.90| -0.90|  1.00| \n",
      "---------------------------\n",
      "-0.90|  0.00| -0.90| -1.00| \n",
      "---------------------------\n",
      "-0.90| -0.90| -0.90| -0.90| \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efc9c2c68d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final policy:\n",
      "---------------------------\n",
      "  R  |   R  |   R  |      | \n",
      "---------------------------\n",
      "  U  |      |   U  |      | \n",
      "---------------------------\n",
      "  U  |   R  |   U  |   U  | \n",
      "final values:\n",
      "---------------------------\n",
      "-0.90|  0.00|  1.00|  0.00| \n",
      "---------------------------\n",
      "-2.25|  0.00|  0.00|  0.00| \n",
      "---------------------------\n",
      "-2.74| -2.09| -0.90| -1.00| \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # use the standard grid again (0 for every step) so that we can compare\n",
    "    # to iterative policy evaluation\n",
    "    # grid = standard_grid()\n",
    "    # try the negative grid too, to see if agent will learn to go past the \"bad spot\"\n",
    "    # in order to minimize number of steps\n",
    "    grid = negative_grid(step_cost=-0.9)\n",
    "\n",
    "    # print rewards\n",
    "    print \"rewards:\"\n",
    "    print_values(grid.rewards, grid)\n",
    "\n",
    "    # state -> action\n",
    "    # initialize a random policy\n",
    "    policy = {}\n",
    "    for s in grid.actions.keys():\n",
    "        policy[s] = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "\n",
    "    # initialize Q(s,a) and returns\n",
    "    Q = {}\n",
    "    returns = {} # dictionary of state -> list of returns we've received\n",
    "    states = grid.all_states()\n",
    "    for s in states:\n",
    "        if s in grid.actions: # not a terminal state\n",
    "            Q[s] = {}\n",
    "            for a in ALL_POSSIBLE_ACTIONS:\n",
    "                Q[s][a] = 0 # needs to be initialized to something so we can argmax it\n",
    "                returns[(s,a)] = []\n",
    "        else:\n",
    "            # terminal state or state we can't otherwise get to\n",
    "            pass\n",
    "\n",
    "    # repeat until convergence\n",
    "    deltas = []\n",
    "    for t in xrange(2000):\n",
    "        if t % 100 == 0:\n",
    "            print t\n",
    "\n",
    "        # generate an episode using pi\n",
    "        biggest_change = 0\n",
    "        states_actions_returns = play_game(grid, policy)\n",
    "        seen_state_action_pairs = set()\n",
    "        for s, a, G in states_actions_returns:\n",
    "            # check if we have already seen s\n",
    "            # called \"first-visit\" MC policy evaluation\n",
    "            sa = (s, a)\n",
    "            if sa not in seen_state_action_pairs:\n",
    "                old_q = Q[s][a]\n",
    "                returns[sa].append(G)\n",
    "                Q[s][a] = np.mean(returns[sa])\n",
    "                biggest_change = max(biggest_change, np.abs(old_q - Q[s][a]))\n",
    "                seen_state_action_pairs.add(sa)\n",
    "        deltas.append(biggest_change)\n",
    "\n",
    "        # update policy\n",
    "        for s in policy.keys():\n",
    "            policy[s] = max_dict(Q[s])[0]\n",
    "\n",
    "    plt.plot(deltas)\n",
    "    plt.show()\n",
    "\n",
    "    print \"final policy:\"\n",
    "    print_policy(policy, grid)\n",
    "\n",
    "    # find V\n",
    "    V = {}\n",
    "    for s, Qs in Q.iteritems():\n",
    "        V[s] = max_dict(Q[s])[1]\n",
    "\n",
    "    print \"final values:\"\n",
    "    print_values(V, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
